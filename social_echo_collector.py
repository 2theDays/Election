"""
ì¶©ë¶ ë„ì§€ì‚¬ í›„ë³´ 'ì—ì½” ì²´ì„ë²„(Echo Chamber)' ë° ì»¤ë®¤ë‹ˆí‹° ë¯¼ì‹¬ ë¶„ì„ê¸°
Phase 2: ì˜¨ë¼ì¸ ì»¤ë®¤ë‹ˆí‹°, ì¹´í˜, ë¸”ë¡œê·¸ì˜ ë°˜ì‘ ë° í”„ë ˆì„ ë¶„ì„
"""

import requests
from bs4 import BeautifulSoup
import json
import pandas as pd
from datetime import datetime
import time
import re
from anthropic import Anthropic
import os

# Claude API ì„¤ì •
client = Anthropic(api_key=os.environ.get("ANTHROPIC_API_KEY"))

class SocialEchoCollector:
    """ì»¤ë®¤ë‹ˆí‹° ë° ì†Œì…œ ë¯¸ë””ì–´ì˜ 'ì—ì½” ì²´ì„ë²„' íš¨ê³¼ì™€ ì—¬ë¡  í”„ë ˆì„ì„ ë¶„ì„í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        with open('candidates_data.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
        self.candidates = [c['name'] for c in data['candidates']]
        self.echo_data = []

    def collect_naver_community(self, keyword, search_type='cafe', max_pages=3):
        """ë„¤ì´ë²„ ì¹´í˜ ë˜ëŠ” ë¸”ë¡œê·¸ì—ì„œ ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘ ìˆ˜ì§‘ (ì‹¤ì§ˆì  ì—ì½” ì²´ì„ë²„)"""
        results = []
        base_url = f"https://search.naver.com/search.naver?where={search_type}&query={keyword}"
        
        print(f"  > ë„¤ì´ë²„ {search_type} ê²€ìƒ‰ ì¤‘: {keyword}")
        
        try:
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
            response = requests.get(base_url, headers=headers)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ê²€ìƒ‰ ê²°ê³¼ í•­ëª© ì¶”ì¶œ (ì¹´í˜/ë¸”ë¡œê·¸ íŒ¨í„´ì— ë”°ë¼ ì¡°ì • í•„ìš”)
            items = soup.select('.api_ani_send') # ë„¤ì´ë²„ ê²€ìƒ‰ ê²°ê³¼ ê³µí†µ í´ë˜ìŠ¤ ì‹œë„
            if not items:
                items = soup.select('.total_wrap') # ëŒ€ì•ˆ íŒ¨í„´
                
            for item in items[:20]: # í˜ì´ì§€ë‹¹ ìƒìœ„ 20ê°œ
                title = item.select_one('.api_txt_lines.total_tit')
                desc = item.select_one('.api_txt_lines.dsc_txt')
                
                if title and desc:
                    results.append({
                        'title': title.get_text(strip=True),
                        'snippet': desc.get_text(strip=True),
                        'source_type': search_type,
                        'keyword': keyword
                    })
            
            return results
        except Exception as e:
            print(f"    âŒ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return []

    def analyze_echo_frames(self, candidate_name, raw_data):
        """ìˆ˜ì§‘ëœ ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘ì—ì„œ ì£¼ëœ 'í”„ë ˆì„'ê³¼ 'ì—ì½”' ê°•ë„ ë¶„ì„"""
        if not raw_data:
            return None
            
        combined_text = "\n".join([f"- {d['title']}: {d['snippet']}" for d in raw_data])
        
        prompt = f"""
ë‹¤ìŒì€ ì¶©ë¶ë„ì§€ì‚¬ í›„ë³´ '{candidate_name}'ì— ëŒ€í•œ ì˜¨ë¼ì¸ ì»¤ë®¤ë‹ˆí‹°(ì¹´í˜, ë¸”ë¡œê·¸ ë“±)ì˜ ë°˜ì‘ë“¤ì…ë‹ˆë‹¤. 
ì´ ë°ì´í„°ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” 'ì—ì½” ì²´ì„ë²„(ë°˜ë³µë˜ëŠ” ì—¬ë¡ ì˜ í‹€)'ë¥¼ ë¶„ì„í•˜ì„¸ìš”.

**ìˆ˜ì§‘ ë°ì´í„°**:
{combined_text}

**ë¶„ì„ ìš”ì²­ ì‚¬í•­ (JSON í˜•ì‹ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”)**:
{{
    "candidate": "{candidate_name}",
    "top_frames": [
        {{
            "frame_name": "í”„ë ˆì„ ëª…ì¹­ (ì˜ˆ: 'í–‰ì •ì „ë¬¸ê°€', 'ë°°ì‹ ì í”„ë ˆì„' ë“±)",
            "sentiment": "ê¸ì •|ë¶€ì •|ì¤‘ë¦½",
            "echo_strength": 0.0-1.0 (ì–¼ë§ˆë‚˜ ë§ì´ ë°˜ë³µë˜ëŠ”ê°€),
            "key_arguments": ["ì£¼ëœ ë…¼ê±° 1", "ì£¼ëœ ë…¼ê±° 2"]
        }}
    ],
    "polarization_index": 0.0-1.0 (ì—¬ë¡ ì´ ì–¼ë§ˆë‚˜ ì–‘ê·¹í™”ë˜ì–´ ìˆëŠ”ê°€),
    "viral_potential": "ë†’ìŒ|ì¤‘ê°„|ë‚®ìŒ",
    "summary": "ì „ë°˜ì ì¸ ë¯¼ì‹¬ ìš”ì•½"
}}

**ì£¼ì˜**: 
1. ì‹¤ì œ ë°ì´í„°ì— ê¸°ë°˜í•˜ì—¬ ë¶„ì„í•˜ì„¸ìš”. 
2. ì •ì¹˜ì  ì¤‘ë¦½ì„ ìœ ì§€í•˜ì„¸ìš”.
"""

        try:
            message = client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=2000,
                messages=[{"role": "user", "content": prompt}]
            )
            
            response_text = message.content[0].text
            json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            if json_match:
                response_text = json_match.group(1)
            
            return json.loads(response_text)
        except Exception as e:
            print(f"    âŒ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None

    def run_analysis(self):
        print("\n" + "="*60)
        print("ğŸš€ Step 2: ì—ì½” ì²´ì„ë²„ ë° ì»¤ë®¤ë‹ˆí‹° í”„ë ˆì„ ë¶„ì„ ì‹œì‘")
        print("="*60)
        
        final_reports = []
        
        for name in self.candidates:
            print(f"\nã€{name} í›„ë³´ ë¶„ì„ã€‘")
            
            # 1. ë°ì´í„° ìˆ˜ì§‘ (ì¹´í˜ + ë¸”ë¡œê·¸)
            cafe_data = self.collect_naver_community(f"{name} ì¶©ë¶ë„ì§€ì‚¬", 'cafe')
            blog_data = self.collect_naver_community(f"{name} ì¶©ë¶ë„ì§€ì‚¬", 'blog')
            total_data = cafe_data + blog_data
            
            if not total_data:
                print(f"  âš ï¸ ìˆ˜ì§‘ëœ ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘ì´ ì—†ìŠµë‹ˆë‹¤.")
                continue
                
            print(f"  âœ… {len(total_data)}ê°œì˜ ë°˜ì‘ ìˆ˜ì§‘ ì™„ë£Œ. í”„ë ˆì„ ë¶„ì„ ì¤‘...")
            
            # 2. í”„ë ˆì„ ë¶„ì„
            report = self.analyze_echo_frames(name, total_data)
            if report:
                final_reports.append(report)
                print(f"  ğŸ“Š ì£¼ìš” í”„ë ˆì„: {report['top_frames'][0]['frame_name']} ({report['top_frames'][0]['sentiment']})")
                print(f"  ğŸ“ˆ ì–‘ê·¹í™” ì§€ìˆ˜: {report['polarization_index']}")
            
            time.sleep(1) # API ë¶€í•˜ ë°©ì§€
            
        # 3. ê²°ê³¼ ì €ì¥
        if final_reports:
            output_file = 'community_sentiment_analysis.json'
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(final_reports, f, ensure_ascii=False, indent=4)
            print(f"\nâœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥: {output_file}")
            
            # CSVë¡œ ìš”ì•½ë³¸ ìƒì„±
            summary_list = []
            for r in final_reports:
                for f in r['top_frames']:
                    summary_list.append({
                        'candidate': r['candidate'],
                        'frame': f['frame_name'],
                        'sentiment': f['sentiment'],
                        'strength': f['echo_strength'],
                        'polarization': r['polarization_index']
                    })
            pd.DataFrame(summary_list).to_csv('community_sentiment_summary.csv', index=False, encoding='utf-8-sig')
            print(f"âœ… ìš”ì•½ CSV ì €ì¥: community_sentiment_summary.csv")

if __name__ == "__main__":
    if not os.environ.get("ANTHROPIC_API_KEY"):
        print("âš ï¸ ANTHROPIC_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        analyzer = SocialEchoCollector()
        analyzer.run_analysis()
